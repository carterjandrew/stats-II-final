{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical analysis of quen llm model outliers\n",
    "**By:** *Carter Andrew*  \n",
    "`11-23-2024`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro\n",
    "Here we have some introduction to the goal of this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspiration\n",
    "TODO: There is some paper talking about how larger language models have a larger number of outliers with extreme values in their weights. I want to do my own investigation to confirm if this is true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "Here we import libraries, set up notebook behaviour, download models, ect..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import zscore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading models\n",
    "We can load our models for each size from `HuggingFace` by using their `transformers` library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    \"Qwen/Qwen2.5-0.5B\",\n",
    "    #\"Qwen/Qwen2.5-3B\",\n",
    "    \"Qwen/Qwen2.5-7B\",\n",
    "#    \"Qwen/Qwen1.5-14B\",\n",
    "#    \"Qwen/Qwen2.5-32B\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraing weight averages\n",
    "We can do the following to get out our numbers to work with\n",
    "1. For each model:\n",
    "2. Aggregate layers\n",
    "3. Compute the number of outliers per layer\n",
    "4. Add our values into a database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qwen/Qwen2.5-0.5B\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'complete' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 12\u001b[0m\n\u001b[1;32m      7\u001b[0m outliers \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      8\u001b[0m     name: np\u001b[38;5;241m.\u001b[39mmean(np\u001b[38;5;241m.\u001b[39mabs(zscore(layer)) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m3\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m name, layer \u001b[38;5;129;01min\u001b[39;00m \n\u001b[1;32m      9\u001b[0m     [(name, param\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mflatten()\u001b[38;5;241m.\u001b[39mnumpy()) \u001b[38;5;28;01mfor\u001b[39;00m name, param \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mnamed_parameters()]\n\u001b[1;32m     10\u001b[0m }\n\u001b[1;32m     11\u001b[0m prop_outliers[name] \u001b[38;5;241m=\u001b[39m outliers\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mcomplete\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'complete' is not defined"
     ]
    }
   ],
   "source": [
    "prop_outliers = {}\n",
    "for name in model_names:\n",
    "    model = AutoModelForCausalLM.from_pretrained(name)\n",
    "    print(name)\n",
    "    model_layer_names = [name for name, param in model.named_parameters()]\n",
    "    self_attn_layer_indicies = [index for index, name in enumerate(model_layer_names) if 'self_attn' in name]\n",
    "    outliers = {\n",
    "        name: np.mean(np.abs(zscore(layer)) > 3) for name, layer in \n",
    "        [(name, param.data.flatten().numpy()) for name, param in model.named_parameters()]\n",
    "    }\n",
    "    prop_outliers[name] = outliers\n",
    "    print(\"Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Qwen/Qwen2.5-0.5B': {'model.embed_tokens.weight': np.float64(0.004873623069205831),\n",
       "  'model.layers.0.self_attn.q_proj.weight': np.float64(0.016381088568239797),\n",
       "  'model.layers.0.self_attn.q_proj.bias': np.float64(0.020089285714285716),\n",
       "  'model.layers.0.self_attn.k_proj.weight': np.float64(0.021144321986607144),\n",
       "  'model.layers.0.self_attn.k_proj.bias': np.float64(0.0390625),\n",
       "  'model.layers.0.self_attn.v_proj.weight': np.float64(0.0089111328125),\n",
       "  'model.layers.0.self_attn.v_proj.bias': np.float64(0.015625),\n",
       "  'model.layers.0.self_attn.o_proj.weight': np.float64(0.011843311543367346),\n",
       "  'model.layers.0.mlp.gate_proj.weight': np.float64(0.007243450422932331),\n",
       "  'model.layers.0.mlp.up_proj.weight': np.float64(0.0037334700276080825),\n",
       "  'model.layers.0.mlp.down_proj.weight': np.float64(0.006113382210408835),\n",
       "  'model.layers.0.input_layernorm.weight': np.float64(0.021205357142857144),\n",
       "  'model.layers.0.post_attention_layernorm.weight': np.float64(0.026785714285714284),\n",
       "  'model.layers.1.self_attn.q_proj.weight': np.float64(0.00982292330994898),\n",
       "  'model.layers.1.self_attn.q_proj.bias': np.float64(0.024553571428571428),\n",
       "  'model.layers.1.self_attn.k_proj.weight': np.float64(0.008893694196428572),\n",
       "  'model.layers.1.self_attn.k_proj.bias': np.float64(0.0234375),\n",
       "  'model.layers.1.self_attn.v_proj.weight': np.float64(0.008902413504464286),\n",
       "  'model.layers.1.self_attn.v_proj.bias': np.float64(0.0078125),\n",
       "  'model.layers.1.self_attn.o_proj.weight': np.float64(0.008148816167091837),\n",
       "  'model.layers.1.mlp.gate_proj.weight': np.float64(0.005661813836348684),\n",
       "  'model.layers.1.mlp.up_proj.weight': np.float64(0.003847738853970865),\n",
       "  'model.layers.1.mlp.down_proj.weight': np.float64(0.00430802653606673),\n",
       "  'model.layers.1.input_layernorm.weight': np.float64(0.018973214285714284),\n",
       "  'model.layers.1.post_attention_layernorm.weight': np.float64(0.0011160714285714285),\n",
       "  'model.layers.2.self_attn.q_proj.weight': np.float64(0.011850785235969387),\n",
       "  'model.layers.2.self_attn.q_proj.bias': np.float64(0.018973214285714284),\n",
       "  'model.layers.2.self_attn.k_proj.weight': np.float64(0.010463169642857142),\n",
       "  'model.layers.2.self_attn.k_proj.bias': np.float64(0.0546875),\n",
       "  'model.layers.2.self_attn.v_proj.weight': np.float64(0.010611397879464286),\n",
       "  'model.layers.2.self_attn.v_proj.bias': np.float64(0.0078125),\n",
       "  'model.layers.2.self_attn.o_proj.weight': np.float64(0.009389449139030613),\n",
       "  'model.layers.2.mlp.gate_proj.weight': np.float64(0.004544136219454887),\n",
       "  'model.layers.2.mlp.up_proj.weight': np.float64(0.0038403962787828946),\n",
       "  'model.layers.2.mlp.down_proj.weight': np.float64(0.004615726327537594),\n",
       "  'model.layers.2.input_layernorm.weight': np.float64(0.029017857142857144),\n",
       "  'model.layers.2.post_attention_layernorm.weight': np.float64(0.002232142857142857),\n",
       "  'model.layers.3.self_attn.q_proj.weight': np.float64(0.012604382573341837),\n",
       "  'model.layers.3.self_attn.q_proj.bias': np.float64(0.021205357142857144),\n",
       "  'model.layers.3.self_attn.k_proj.weight': np.float64(0.011143275669642858),\n",
       "  'model.layers.3.self_attn.k_proj.bias': np.float64(0.0234375),\n",
       "  'model.layers.3.self_attn.v_proj.weight': np.float64(0.006504603794642857),\n",
       "  'model.layers.3.self_attn.v_proj.bias': np.float64(0.015625),\n",
       "  'model.layers.3.self_attn.o_proj.weight': np.float64(0.009942502391581632),\n",
       "  'model.layers.3.mlp.gate_proj.weight': np.float64(0.0047940132313204886),\n",
       "  'model.layers.3.mlp.up_proj.weight': np.float64(0.004125609433740601),\n",
       "  'model.layers.3.mlp.down_proj.weight': np.float64(0.0049117238898026315),\n",
       "  'model.layers.3.input_layernorm.weight': np.float64(0.017857142857142856),\n",
       "  'model.layers.3.post_attention_layernorm.weight': np.float64(0.002232142857142857),\n",
       "  'model.layers.4.self_attn.q_proj.weight': np.float64(0.011067293128188776),\n",
       "  'model.layers.4.self_attn.q_proj.bias': np.float64(0.017857142857142856),\n",
       "  'model.layers.4.self_attn.k_proj.weight': np.float64(0.00958251953125),\n",
       "  'model.layers.4.self_attn.k_proj.bias': np.float64(0.0234375),\n",
       "  'model.layers.4.self_attn.v_proj.weight': np.float64(0.0068359375),\n",
       "  'model.layers.4.self_attn.v_proj.bias': np.float64(0.0390625),\n",
       "  'model.layers.4.self_attn.o_proj.weight': np.float64(0.01050178372130102),\n",
       "  'model.layers.4.mlp.gate_proj.weight': np.float64(0.006846492451832707),\n",
       "  'model.layers.4.mlp.up_proj.weight': np.float64(0.00472288203418703),\n",
       "  'model.layers.4.mlp.down_proj.weight': np.float64(0.005666402945841165),\n",
       "  'model.layers.4.input_layernorm.weight': np.float64(0.013392857142857142),\n",
       "  'model.layers.4.post_attention_layernorm.weight': np.float64(0.005580357142857143),\n",
       "  'model.layers.5.self_attn.q_proj.weight': np.float64(0.012229452327806123),\n",
       "  'model.layers.5.self_attn.q_proj.bias': np.float64(0.016741071428571428),\n",
       "  'model.layers.5.self_attn.k_proj.weight': np.float64(0.012137276785714286),\n",
       "  'model.layers.5.self_attn.k_proj.bias': np.float64(0.015625),\n",
       "  'model.layers.5.self_attn.v_proj.weight': np.float64(0.005571637834821429),\n",
       "  'model.layers.5.self_attn.v_proj.bias': np.float64(0.0234375),\n",
       "  'model.layers.5.self_attn.o_proj.weight': np.float64(0.008563606106505101),\n",
       "  'model.layers.5.mlp.gate_proj.weight': np.float64(0.006954107069431391),\n",
       "  'model.layers.5.mlp.up_proj.weight': np.float64(0.004354147086466165),\n",
       "  'model.layers.5.mlp.down_proj.weight': np.float64(0.005576685855263158),\n",
       "  'model.layers.5.input_layernorm.weight': np.float64(0.013392857142857142),\n",
       "  'model.layers.5.post_attention_layernorm.weight': np.float64(0.0033482142857142855),\n",
       "  'model.layers.6.self_attn.q_proj.weight': np.float64(0.013083944515306123),\n",
       "  'model.layers.6.self_attn.q_proj.bias': np.float64(0.026785714285714284),\n",
       "  'model.layers.6.self_attn.k_proj.weight': np.float64(0.010977608816964286),\n",
       "  'model.layers.6.self_attn.k_proj.bias': np.float64(0.0078125),\n",
       "  'model.layers.6.self_attn.v_proj.weight': np.float64(0.007158551897321429),\n",
       "  'model.layers.6.self_attn.v_proj.bias': np.float64(0.0),\n",
       "  'model.layers.6.self_attn.o_proj.weight': np.float64(0.01046939772002551),\n",
       "  'model.layers.6.mlp.gate_proj.weight': np.float64(0.005476643268327068),\n",
       "  'model.layers.6.mlp.up_proj.weight': np.float64(0.004565246123120301),\n",
       "  'model.layers.6.mlp.down_proj.weight': np.float64(0.005477102179276316),\n",
       "  'model.layers.6.input_layernorm.weight': np.float64(0.016741071428571428),\n",
       "  'model.layers.6.post_attention_layernorm.weight': np.float64(0.0011160714285714285),\n",
       "  'model.layers.7.self_attn.q_proj.weight': np.float64(0.010374730947066327),\n",
       "  'model.layers.7.self_attn.q_proj.bias': np.float64(0.015625),\n",
       "  'model.layers.7.self_attn.k_proj.weight': np.float64(0.010227748325892858),\n",
       "  'model.layers.7.self_attn.k_proj.bias': np.float64(0.015625),\n",
       "  'model.layers.7.self_attn.v_proj.weight': np.float64(0.005336216517857143),\n",
       "  'model.layers.7.self_attn.v_proj.bias': np.float64(0.0234375),\n",
       "  'model.layers.7.self_attn.o_proj.weight': np.float64(0.009055624202806123),\n",
       "  'model.layers.7.mlp.gate_proj.weight': np.float64(0.006643424356790413),\n",
       "  'model.layers.7.mlp.up_proj.weight': np.float64(0.0055438737223919175),\n",
       "  'model.layers.7.mlp.down_proj.weight': np.float64(0.006853146660596805),\n",
       "  'model.layers.7.input_layernorm.weight': np.float64(0.011160714285714286),\n",
       "  'model.layers.7.post_attention_layernorm.weight': np.float64(0.0011160714285714285),\n",
       "  'model.layers.8.self_attn.q_proj.weight': np.float64(0.011185626594387755),\n",
       "  'model.layers.8.self_attn.q_proj.bias': np.float64(0.021205357142857144),\n",
       "  'model.layers.8.self_attn.k_proj.weight': np.float64(0.010079520089285714),\n",
       "  'model.layers.8.self_attn.k_proj.bias': np.float64(0.0234375),\n",
       "  'model.layers.8.self_attn.v_proj.weight': np.float64(0.008954729352678572),\n",
       "  'model.layers.8.self_attn.v_proj.bias': np.float64(0.0),\n",
       "  'model.layers.8.self_attn.o_proj.weight': np.float64(0.009783063616071428),\n",
       "  'model.layers.8.mlp.gate_proj.weight': np.float64(0.007802403959116542),\n",
       "  'model.layers.8.mlp.up_proj.weight': np.float64(0.005525058373472744),\n",
       "  'model.layers.8.mlp.down_proj.weight': np.float64(0.006607170391799812),\n",
       "  'model.layers.8.input_layernorm.weight': np.float64(0.022321428571428572),\n",
       "  'model.layers.8.post_attention_layernorm.weight': np.float64(0.0),\n",
       "  'model.layers.9.self_attn.q_proj.weight': np.float64(0.014114068478954082),\n",
       "  'model.layers.9.self_attn.q_proj.bias': np.float64(0.026785714285714284),\n",
       "  'model.layers.9.self_attn.k_proj.weight': np.float64(0.012381417410714286),\n",
       "  'model.layers.9.self_attn.k_proj.bias': np.float64(0.03125),\n",
       "  'model.layers.9.self_attn.v_proj.weight': np.float64(0.006495884486607143),\n",
       "  'model.layers.9.self_attn.v_proj.bias': np.float64(0.015625),\n",
       "  'model.layers.9.self_attn.o_proj.weight': np.float64(0.01055160833864796),\n",
       "  'model.layers.9.mlp.gate_proj.weight': np.float64(0.007601400963345864),\n",
       "  'model.layers.9.mlp.up_proj.weight': np.float64(0.006046840122767857),\n",
       "  'model.layers.9.mlp.down_proj.weight': np.float64(0.007721635632048873),\n",
       "  'model.layers.9.input_layernorm.weight': np.float64(0.017857142857142856),\n",
       "  'model.layers.9.post_attention_layernorm.weight': np.float64(0.0),\n",
       "  'model.layers.10.self_attn.q_proj.weight': np.float64(0.011225486288265306),\n",
       "  'model.layers.10.self_attn.q_proj.bias': np.float64(0.018973214285714284),\n",
       "  'model.layers.10.self_attn.k_proj.weight': np.float64(0.011143275669642858),\n",
       "  'model.layers.10.self_attn.k_proj.bias': np.float64(0.015625),\n",
       "  'model.layers.10.self_attn.v_proj.weight': np.float64(0.00909423828125),\n",
       "  'model.layers.10.self_attn.v_proj.bias': np.float64(0.015625),\n",
       "  'model.layers.10.self_attn.o_proj.weight': np.float64(0.011663942920918368),\n",
       "  'model.layers.10.mlp.gate_proj.weight': np.float64(0.008587600593280075),\n",
       "  'model.layers.10.mlp.up_proj.weight': np.float64(0.005745335629111842),\n",
       "  'model.layers.10.mlp.down_proj.weight': np.float64(0.007359554893092105),\n",
       "  'model.layers.10.input_layernorm.weight': np.float64(0.006696428571428571),\n",
       "  'model.layers.10.post_attention_layernorm.weight': np.float64(0.0033482142857142855),\n",
       "  'model.layers.11.self_attn.q_proj.weight': np.float64(0.016453334263392856),\n",
       "  'model.layers.11.self_attn.q_proj.bias': np.float64(0.018973214285714284),\n",
       "  'model.layers.11.self_attn.k_proj.weight': np.float64(0.017682756696428572),\n",
       "  'model.layers.11.self_attn.k_proj.bias': np.float64(0.0234375),\n",
       "  'model.layers.11.self_attn.v_proj.weight': np.float64(0.006617954799107143),\n",
       "  'model.layers.11.self_attn.v_proj.bias': np.float64(0.0234375),\n",
       "  'model.layers.11.self_attn.o_proj.weight': np.float64(0.012173399633290817),\n",
       "  'model.layers.11.mlp.gate_proj.weight': np.float64(0.008234009706884399),\n",
       "  'model.layers.11.mlp.up_proj.weight': np.float64(0.006261380991541354),\n",
       "  'model.layers.11.mlp.down_proj.weight': np.float64(0.007495851445018797),\n",
       "  'model.layers.11.input_layernorm.weight': np.float64(0.021205357142857144),\n",
       "  'model.layers.11.post_attention_layernorm.weight': np.float64(0.0),\n",
       "  'model.layers.12.self_attn.q_proj.weight': np.float64(0.011127082669005101),\n",
       "  'model.layers.12.self_attn.q_proj.bias': np.float64(0.026785714285714284),\n",
       "  'model.layers.12.self_attn.k_proj.weight': np.float64(0.010062081473214286),\n",
       "  'model.layers.12.self_attn.k_proj.bias': np.float64(0.0234375),\n",
       "  'model.layers.12.self_attn.v_proj.weight': np.float64(0.006678989955357143),\n",
       "  'model.layers.12.self_attn.v_proj.bias': np.float64(0.015625),\n",
       "  'model.layers.12.self_attn.o_proj.weight': np.float64(0.010133081552933673),\n",
       "  'model.layers.12.mlp.gate_proj.weight': np.float64(0.009060508326480263),\n",
       "  'model.layers.12.mlp.up_proj.weight': np.float64(0.00623178123531485),\n",
       "  'model.layers.12.mlp.down_proj.weight': np.float64(0.00714340783599624),\n",
       "  'model.layers.12.input_layernorm.weight': np.float64(0.0033482142857142855),\n",
       "  'model.layers.12.post_attention_layernorm.weight': np.float64(0.0011160714285714285),\n",
       "  'model.layers.13.self_attn.q_proj.weight': np.float64(0.013913524394132654),\n",
       "  'model.layers.13.self_attn.q_proj.bias': np.float64(0.016741071428571428),\n",
       "  'model.layers.13.self_attn.k_proj.weight': np.float64(0.013401576450892858),\n",
       "  'model.layers.13.self_attn.k_proj.bias': np.float64(0.0234375),\n",
       "  'model.layers.13.self_attn.v_proj.weight': np.float64(0.007167271205357143),\n",
       "  'model.layers.13.self_attn.v_proj.bias': np.float64(0.0234375),\n",
       "  'model.layers.13.self_attn.o_proj.weight': np.float64(0.00998111647002551),\n",
       "  'model.layers.13.mlp.gate_proj.weight': np.float64(0.009524467296170113),\n",
       "  'model.layers.13.mlp.up_proj.weight': np.float64(0.007087650155662594),\n",
       "  'model.layers.13.mlp.down_proj.weight': np.float64(0.007775098757636279),\n",
       "  'model.layers.13.input_layernorm.weight': np.float64(0.0033482142857142855),\n",
       "  'model.layers.13.post_attention_layernorm.weight': np.float64(0.0),\n",
       "  'model.layers.14.self_attn.q_proj.weight': np.float64(0.012538364955357142),\n",
       "  'model.layers.14.self_attn.q_proj.bias': np.float64(0.020089285714285716),\n",
       "  'model.layers.14.self_attn.k_proj.weight': np.float64(0.010349818638392858),\n",
       "  'model.layers.14.self_attn.k_proj.bias': np.float64(0.0234375),\n",
       "  'model.layers.14.self_attn.v_proj.weight': np.float64(0.010986328125),\n",
       "  'model.layers.14.self_attn.v_proj.bias': np.float64(0.015625),\n",
       "  'model.layers.14.self_attn.o_proj.weight': np.float64(0.010588976801658163),\n",
       "  'model.layers.14.mlp.gate_proj.weight': np.float64(0.00923328829887218),\n",
       "  'model.layers.14.mlp.up_proj.weight': np.float64(0.006432095864661654),\n",
       "  'model.layers.14.mlp.down_proj.weight': np.float64(0.007119773922109962),\n",
       "  'model.layers.14.input_layernorm.weight': np.float64(0.0),\n",
       "  'model.layers.14.post_attention_layernorm.weight': np.float64(0.0),\n",
       "  'model.layers.15.self_attn.q_proj.weight': np.float64(0.01129897759885204),\n",
       "  'model.layers.15.self_attn.q_proj.bias': np.float64(0.020089285714285716),\n",
       "  'model.layers.15.self_attn.k_proj.weight': np.float64(0.012233189174107142),\n",
       "  'model.layers.15.self_attn.k_proj.bias': np.float64(0.015625),\n",
       "  'model.layers.15.self_attn.v_proj.weight': np.float64(0.008187430245535714),\n",
       "  'model.layers.15.self_attn.v_proj.bias': np.float64(0.015625),\n",
       "  'model.layers.15.self_attn.o_proj.weight': np.float64(0.01119808274872449),\n",
       "  'model.layers.15.mlp.gate_proj.weight': np.float64(0.00869292065613252),\n",
       "  'model.layers.15.mlp.up_proj.weight': np.float64(0.0067361243685385335),\n",
       "  'model.layers.15.mlp.down_proj.weight': np.float64(0.007704885382401316),\n",
       "  'model.layers.15.input_layernorm.weight': np.float64(0.020089285714285716),\n",
       "  'model.layers.15.post_attention_layernorm.weight': np.float64(0.0033482142857142855),\n",
       "  'model.layers.16.self_attn.q_proj.weight': np.float64(0.01654426419005102),\n",
       "  'model.layers.16.self_attn.q_proj.bias': np.float64(0.016741071428571428),\n",
       "  'model.layers.16.self_attn.k_proj.weight': np.float64(0.013741629464285714),\n",
       "  'model.layers.16.self_attn.k_proj.bias': np.float64(0.03125),\n",
       "  'model.layers.16.self_attn.v_proj.weight': np.float64(0.025320870535714284),\n",
       "  'model.layers.16.self_attn.v_proj.bias': np.float64(0.015625),\n",
       "  'model.layers.16.self_attn.o_proj.weight': np.float64(0.014251086176658163),\n",
       "  'model.layers.16.mlp.gate_proj.weight': np.float64(0.009121772938204887),\n",
       "  'model.layers.16.mlp.up_proj.weight': np.float64(0.0062762955973919175),\n",
       "  'model.layers.16.mlp.down_proj.weight': np.float64(0.006125313895089286),\n",
       "  'model.layers.16.input_layernorm.weight': np.float64(0.020089285714285716),\n",
       "  'model.layers.16.post_attention_layernorm.weight': np.float64(0.006696428571428571),\n",
       "  'model.layers.17.self_attn.q_proj.weight': np.float64(0.011667679767219387),\n",
       "  'model.layers.17.self_attn.q_proj.bias': np.float64(0.016741071428571428),\n",
       "  'model.layers.17.self_attn.k_proj.weight': np.float64(0.01153564453125),\n",
       "  'model.layers.17.self_attn.k_proj.bias': np.float64(0.0234375),\n",
       "  'model.layers.17.self_attn.v_proj.weight': np.float64(0.008823939732142858),\n",
       "  'model.layers.17.self_attn.v_proj.bias': np.float64(0.0078125),\n",
       "  'model.layers.17.self_attn.o_proj.weight': np.float64(0.008257184709821428),\n",
       "  'model.layers.17.mlp.gate_proj.weight': np.float64(0.007860456194196428),\n",
       "  'model.layers.17.mlp.up_proj.weight': np.float64(0.004719669657542293),\n",
       "  'model.layers.17.mlp.down_proj.weight': np.float64(0.005243287050634399),\n",
       "  'model.layers.17.input_layernorm.weight': np.float64(0.011160714285714286),\n",
       "  'model.layers.17.post_attention_layernorm.weight': np.float64(0.015625),\n",
       "  'model.layers.18.self_attn.q_proj.weight': np.float64(0.011210538903061224),\n",
       "  'model.layers.18.self_attn.q_proj.bias': np.float64(0.021205357142857144),\n",
       "  'model.layers.18.self_attn.k_proj.weight': np.float64(0.008719308035714286),\n",
       "  'model.layers.18.self_attn.k_proj.bias': np.float64(0.015625),\n",
       "  'model.layers.18.self_attn.v_proj.weight': np.float64(0.005719866071428571),\n",
       "  'model.layers.18.self_attn.v_proj.bias': np.float64(0.0234375),\n",
       "  'model.layers.18.self_attn.o_proj.weight': np.float64(0.00844402702487245),\n",
       "  'model.layers.18.mlp.gate_proj.weight': np.float64(0.006272165398848684),\n",
       "  'model.layers.18.mlp.up_proj.weight': np.float64(0.004282327522908835),\n",
       "  'model.layers.18.mlp.down_proj.weight': np.float64(0.005124888025728383),\n",
       "  'model.layers.18.input_layernorm.weight': np.float64(0.010044642857142858),\n",
       "  'model.layers.18.post_attention_layernorm.weight': np.float64(0.005580357142857143),\n",
       "  'model.layers.19.self_attn.q_proj.weight': np.float64(0.010800731425382654),\n",
       "  'model.layers.19.self_attn.q_proj.bias': np.float64(0.016741071428571428),\n",
       "  'model.layers.19.self_attn.k_proj.weight': np.float64(0.008074079241071428),\n",
       "  'model.layers.19.self_attn.k_proj.bias': np.float64(0.015625),\n",
       "  'model.layers.19.self_attn.v_proj.weight': np.float64(0.00531005859375),\n",
       "  'model.layers.19.self_attn.v_proj.bias': np.float64(0.0234375),\n",
       "  'model.layers.19.self_attn.o_proj.weight': np.float64(0.01009944993622449),\n",
       "  'model.layers.19.mlp.gate_proj.weight': np.float64(0.007558492789591165),\n",
       "  'model.layers.19.mlp.up_proj.weight': np.float64(0.005116398173167293),\n",
       "  'model.layers.19.mlp.down_proj.weight': np.float64(0.006013339623472744),\n",
       "  'model.layers.19.input_layernorm.weight': np.float64(0.03125),\n",
       "  'model.layers.19.post_attention_layernorm.weight': np.float64(0.008928571428571428),\n",
       "  'model.layers.20.self_attn.q_proj.weight': np.float64(0.013421506297831632),\n",
       "  'model.layers.20.self_attn.q_proj.bias': np.float64(0.0234375),\n",
       "  'model.layers.20.self_attn.k_proj.weight': np.float64(0.011884416852678572),\n",
       "  'model.layers.20.self_attn.k_proj.bias': np.float64(0.015625),\n",
       "  'model.layers.20.self_attn.v_proj.weight': np.float64(0.016836983816964284),\n",
       "  'model.layers.20.self_attn.v_proj.bias': np.float64(0.0078125),\n",
       "  'model.layers.20.self_attn.o_proj.weight': np.float64(0.009530203683035714),\n",
       "  'model.layers.20.mlp.gate_proj.weight': np.float64(0.007544496005639098),\n",
       "  'model.layers.20.mlp.up_proj.weight': np.float64(0.005246958338228383),\n",
       "  'model.layers.20.mlp.down_proj.weight': np.float64(0.005823579945958646),\n",
       "  'model.layers.20.input_layernorm.weight': np.float64(0.027901785714285716),\n",
       "  'model.layers.20.post_attention_layernorm.weight': np.float64(0.017857142857142856),\n",
       "  'model.layers.21.self_attn.q_proj.weight': np.float64(0.016130719866071428),\n",
       "  'model.layers.21.self_attn.q_proj.bias': np.float64(0.024553571428571428),\n",
       "  'model.layers.21.self_attn.k_proj.weight': np.float64(0.012581961495535714),\n",
       "  'model.layers.21.self_attn.k_proj.bias': np.float64(0.03125),\n",
       "  'model.layers.21.self_attn.v_proj.weight': np.float64(0.014229910714285714),\n",
       "  'model.layers.21.self_attn.v_proj.bias': np.float64(0.0078125),\n",
       "  'model.layers.21.self_attn.o_proj.weight': np.float64(0.007691675302933673),\n",
       "  'model.layers.21.mlp.gate_proj.weight': np.float64(0.00569829725681391),\n",
       "  'model.layers.21.mlp.up_proj.weight': np.float64(0.003992066347509399),\n",
       "  'model.layers.21.mlp.down_proj.weight': np.float64(0.004961515727796052),\n",
       "  'model.layers.21.input_layernorm.weight': np.float64(0.03459821428571429),\n",
       "  'model.layers.21.post_attention_layernorm.weight': np.float64(0.014508928571428572),\n",
       "  'model.layers.22.self_attn.q_proj.weight': np.float64(0.015925193319515307),\n",
       "  'model.layers.22.self_attn.q_proj.bias': np.float64(0.03236607142857143),\n",
       "  'model.layers.22.self_attn.k_proj.weight': np.float64(0.012956891741071428),\n",
       "  'model.layers.22.self_attn.k_proj.bias': np.float64(0.0234375),\n",
       "  'model.layers.22.self_attn.v_proj.weight': np.float64(0.01556396484375),\n",
       "  'model.layers.22.self_attn.v_proj.bias': np.float64(0.015625),\n",
       "  'model.layers.22.self_attn.o_proj.weight': np.float64(0.0061508490114795915),\n",
       "  'model.layers.22.mlp.gate_proj.weight': np.float64(0.005344706370418233),\n",
       "  'model.layers.22.mlp.up_proj.weight': np.float64(0.0041214792351973685),\n",
       "  'model.layers.22.mlp.down_proj.weight': np.float64(0.0043438215901080825),\n",
       "  'model.layers.22.input_layernorm.weight': np.float64(0.015625),\n",
       "  'model.layers.22.post_attention_layernorm.weight': np.float64(0.024553571428571428),\n",
       "  'model.layers.23.self_attn.q_proj.weight': np.float64(0.018000388632015307),\n",
       "  'model.layers.23.self_attn.q_proj.bias': np.float64(0.024553571428571428),\n",
       "  'model.layers.23.self_attn.k_proj.weight': np.float64(0.011858258928571428),\n",
       "  'model.layers.23.self_attn.k_proj.bias': np.float64(0.03125),\n",
       "  'model.layers.23.self_attn.v_proj.weight': np.float64(0.009992327008928572),\n",
       "  'model.layers.23.self_attn.v_proj.bias': np.float64(0.0),\n",
       "  'model.layers.23.self_attn.o_proj.weight': np.float64(0.010453204719387755),\n",
       "  'model.layers.23.mlp.gate_proj.weight': np.float64(0.005508767034774436),\n",
       "  'model.layers.23.mlp.up_proj.weight': np.float64(0.004277967868890977),\n",
       "  'model.layers.23.mlp.down_proj.weight': np.float64(0.005731797756109023),\n",
       "  'model.layers.23.input_layernorm.weight': np.float64(0.03794642857142857),\n",
       "  'model.layers.23.post_attention_layernorm.weight': np.float64(0.016741071428571428),\n",
       "  'model.norm.weight': np.float64(0.030133928571428572)}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prop_outliers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
